{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposta nova:**\n",
    "- Uso de LLM para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\dev\\mestrado\\.venv\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\dev\\mestrado\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\dev\\mestrado\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\dev\\mestrado\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\dev\\mestrado\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.7.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.58.1 pydantic-2.10.4 pydantic-core-2.27.2 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install --upgrade numpy\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# %pip install ipywidgets\n",
    "# %pip install tensorflow\n",
    "# %pip install --upgrade gensim\n",
    "# %pip install python-dotenv\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inicio | Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_PROJECT = os.getenv(\"OPENAI_PROJECT_ID\")\n",
    "OPENAI_APIKEY = os.getenv(\"OPENAI_APIKEY\")\n",
    "\n",
    "## Authenticate with OpenAI via CURL\n",
    "# !curl https://api.openai.com/v1/models -H \"Authorization: Bearer $OPENAI_APIKEY\" -H \"OpenAI-Project: $OPENAI_PROJECT\"\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from string import punctuation\n",
    "# from keras.layers import TextVectorization\n",
    "# from gensim import utils\n",
    "# import gensim.models\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import re # Regular Expression\n",
    "# import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venue</th>\n",
       "      <th>Review ID</th>\n",
       "      <th>review</th>\n",
       "      <th>Tone</th>\n",
       "      <th>Review URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ShitMyReviewerSay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is early in the year, but difficult to imag...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ShitMyReviewerSay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You do not use the empirical data for the anal...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ShitMyReviewerSay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I understand that Wikipedia is not the best so...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ShitMyReviewerSay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reviewer #1: 'The project can hardly be descri...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Venue Review ID  \\\n",
       "0  ShitMyReviewerSay       NaN   \n",
       "1  ShitMyReviewerSay       NaN   \n",
       "2  ShitMyReviewerSay       NaN   \n",
       "3  ShitMyReviewerSay       NaN   \n",
       "\n",
       "                                              review  Tone Review URL  \n",
       "0  It is early in the year, but difficult to imag...     2        NaN  \n",
       "1  You do not use the empirical data for the anal...     2        NaN  \n",
       "2  I understand that Wikipedia is not the best so...     3        NaN  \n",
       "3  Reviewer #1: 'The project can hardly be descri...     3        NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'PolitenessDataset-FULL.csv'\n",
    "\n",
    "# Original Dataframe\n",
    "OriginalPolitenessDF = pd.read_csv(path)\n",
    "# print('Data Stats:', OriginalPolitenessDF.describe())\n",
    "\n",
    "# Experiments Dataframe\n",
    "TargetDf = OriginalPolitenessDF.copy()\n",
    "\n",
    "TargetDf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>CodeVenue</th>\n",
       "      <th>review</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>It is early in the year, but difficult to imag...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>You do not use the empirical data for the anal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>I understand that Wikipedia is not the best so...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Reviewer #1: 'The project can hardly be descri...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>The figures are dishonest and not all that use...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  CodeVenue                                             review  Tone\n",
       "0      0          3  It is early in the year, but difficult to imag...     2\n",
       "1      1          3  You do not use the empirical data for the anal...     2\n",
       "2      2          3  I understand that Wikipedia is not the best so...     3\n",
       "3      3          3  Reviewer #1: 'The project can hardly be descri...     3\n",
       "4      4          3  The figures are dishonest and not all that use...     2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Transformations:\n",
    "\n",
    "# Codificação\n",
    "TargetDf['CodeVenue'] = TargetDf['Venue'].astype('category').cat.codes\n",
    "# ReviewId\n",
    "TargetDf['Index'] = TargetDf.index\n",
    "# Reorder\n",
    "TargetDf = TargetDf[['Index', 'CodeVenue', 'review', 'Tone']]\n",
    "TargetDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>CodeVenue</th>\n",
       "      <th>review</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>I am also curious with the effect of pre train...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  CodeVenue                                             review  \\\n",
       "1600   1600          0  I am also curious with the effect of pre train...   \n",
       "\n",
       "      Tone  \n",
       "1600     2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### OpenAi Call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample Text:', '- This sounds somewhat vague .', '\\nTone:', 3]\n",
      "('3 - Neutral.\\n'\n",
      " '\\n'\n",
      " 'The comment \"This sounds somewhat vague\" is neutral as it identifies an area '\n",
      " 'of improvement without using offensive or disrespectful language. It '\n",
      " 'provides a straightforward observation without embellishment or softened '\n",
      " 'language.')\n"
     ]
    }
   ],
   "source": [
    "# Test Sample\n",
    "X = TargetDf.sample(1)\n",
    "X_text = X['review'].values[0]\n",
    "X_tone = X['Tone'].values[0]\n",
    "pprint(['Sample Text:', X_text, '\\nTone:', X_tone])\n",
    "\n",
    "# ChatGPT:\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_APIKEY,\n",
    "    project=OPENAI_PROJECT\n",
    ")\n",
    "\n",
    "Sample1 = X_text\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":   \"You are a helpful technical assistant,\\\n",
    "                                        specialist in non violent communication, politeness and all communication matters.\\\n",
    "                                        You are rating texts on a scale of 1 to 5 for politeness, from Highly Impolite (1) to Highly Polite (5).\"}, \n",
    "        {\"role\": \"user\", \"content\":     \"I need help with a Peer Review comment.\\\n",
    "                                        in a scale of 1 - 5 classify the comment about it's Politeness.\\\n",
    "                                        How to classify (in a range):\\\n",
    "                                        Highly Impolite (1): Comments containing unnecessarily offensive, sarcastic,\\\n",
    "                                        or disrespectful critiques, using derogatory terms or expressing disdain for the reviewed work.\\\n",
    "                                        Highly Polite (5): Comments explicitly emphasizing positive aspects, using linguistic mitigations,\\\n",
    "                                        direct praise, and respectful language to convey critiques or suggestions.\\\n",
    "                                        Neutral (3) would be a comment that is neither polite nor impolite.\\\n",
    "                                        Bring the rank first, then after a 2 line explanation why, of this comment:\"+Sample1},\n",
    "    ]\n",
    ")\n",
    "\n",
    "pprint(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem que passar mais instruções para o GPT ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a file with the response:\n",
    "\n",
    "with open(\"resposta1.md\", \"w\") as f:\n",
    "    f.write(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(test[['review','Tone']], test['Tone'], test_size=0.2, random_state=42)\n",
    "\n",
    "# max_length = X_train['review'].str.len().max()\n",
    "# print(f\"The maximum length of characters is: {max_length}\")\n",
    "\n",
    "# # Lengths of each review\n",
    "# lengths = X_train['review'].dropna().astype(str).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some visuals\n",
    "\n",
    "# Plotting the distribution of the sources\n",
    "PolitenessDF['Venue'].value_counts().plot(title='Sources Freq', kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Tone distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(PolitenessDF['Tone'], bins=5, fill=True, color='blue', edgecolor='black')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(ticks=[1, 2, 3, 4, 5])\n",
    "plt.title(\"Histogram of Politeness Tones\", fontsize=16)\n",
    "plt.xlabel(\"Tone\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Plot tone per venue, stacked\n",
    "PolitenessDF.groupby(['Venue', 'Tone']).size().unstack().plot(kind='bar', stacked=True, title='Tone per Venue')\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram of review lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(lengths, bins=30, kde=True, color='blue', alpha=0.7)  # Seaborn for enhanced visuals\n",
    "plt.title(\"Histogram of Review Lengths\", fontsize=16)\n",
    "plt.xlabel(\"Review Length (characters)\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "clear_output() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Characters: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "##  TODO: Tirar reviews pequenas\n",
    "\n",
    "print('Special Characters:', punctuation)\n",
    "\n",
    "# stop_words = stopwords.words('portuguese')\n",
    "def preprocess(x: str):\n",
    "    new_x = x.replace(r'\"',' ')\n",
    "    for c in punctuation:\n",
    "        new_x = new_x.replace(c,' ')\n",
    "    pattern = r\"\"\"\n",
    "    [^\\w\\s]|         # Remove punctuation\n",
    "    http\\S+|         # Remove links\n",
    "    @\\w+|            # Remove mentions\n",
    "    #\\S+|            # Remove hashtags\n",
    "    \\b\\w*\\d\\w*\\b|    # Remove words containing numbers\n",
    "    \\s+              # Normalize spaces\n",
    "    \"\"\"    \n",
    "    new_x = re.sub(pattern, ' ', new_x, flags=re.VERBOSE) #removendo pontuação do texto\n",
    "    return new_x.lower().strip()\n",
    "\n",
    "df_train = X_train.dropna().copy()\n",
    "df_test = X_test.dropna().copy()\n",
    "\n",
    "## Pré-processar datasets de treino e teste\n",
    "## Dados de treino\n",
    "df_train['review_original'] = df_train['review']\n",
    "df_train['review'] = df_train['review'].apply(preprocess)\n",
    "\n",
    "## Dados de teste\n",
    "df_test['review_original'] = df_test['review']\n",
    "df_test['review'] = df_test['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The strength of this paper is that it both gives a more systematic framework for and builds on existing ideas ( character based models , using dictionary definitions ) to implement them as part of a model trained on the end task .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample (só para ver o processo mesmo)\n",
    "df_train[df_train['Tone'] == 5].sample(1)['review_original'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** LOADED  *****\n",
      "\n",
      "TRAIN SHAPE : (4556, 768)\n",
      "TEST SHAPE : (855, 768)\n",
      "VAL SHAPE : (284, 768)\n",
      "Y-TRAIN SHAPE : (4556, 5)\n",
      "Y-TEST SHAPE : (855, 5)\n",
      "Y-VAL SHAPE : (284, 5)\n"
     ]
    }
   ],
   "source": [
    "## Embbedings pré-treinadas\n",
    "\n",
    "### HYPERPARAMETERS (from notebooks)\n",
    "POLITENESS_LEVELS = 5\n",
    "EPOCHS = 30\n",
    "MAXLEN = 768 # Since SciBERT returns 768 embeddings vector\n",
    "LSTM_UNITS = 256\n",
    "VOCAB_LEN = 1853\n",
    "EMBEDDING_DIMENSION = 768\n",
    "\n",
    "import pickle\n",
    "\n",
    "# LOAD EMBEDS DATASET\n",
    "def loadPickle(name,is_BiLSTM):\n",
    "    start_path = '../PolitePEER/'\n",
    "    if is_BiLSTM:\n",
    "        LOAD_PATH = start_path+'Tokennized_Processed_X_train-BiLSTM.csv'\n",
    "        train_embeds = pd.read_csv(LOAD_PATH)\n",
    "        \n",
    "        LOAD_PATH = start_path+'Tokennized_Processed_X_test-BiLSTM.csv'\n",
    "        test_embeds = pd.read_csv(LOAD_PATH)\n",
    "        \n",
    "        LOAD_PATH = start_path+'Tokennized_Processed_X_val-BiLSTM.csv'\n",
    "        val_embeds = pd.read_csv(LOAD_PATH)\n",
    "        \n",
    "    else:\n",
    "        LOAD_PATH = start_path+name+'_train.pickle'\n",
    "        with open(LOAD_PATH, 'rb') as handle:\n",
    "            train_embeds = pickle.load(handle)\n",
    "            handle.close()\n",
    "\n",
    "        LOAD_PATH = start_path+name+'_test.pickle'\n",
    "        with open(LOAD_PATH, 'rb') as handle:\n",
    "            test_embeds = pickle.load(handle)\n",
    "            handle.close()\n",
    "\n",
    "        LOAD_PATH = start_path+name+'_val.pickle'\n",
    "        with open(LOAD_PATH, 'rb') as handle:\n",
    "            val_embeds = pickle.load(handle)\n",
    "            handle.close()\n",
    "\n",
    "    y_train = pd.read_csv(start_path+'y_train.csv')\n",
    "    y_val = pd.read_csv(start_path+'y_val.csv')\n",
    "    y_test = pd.read_csv(start_path+'y_test.csv')\n",
    "\n",
    "    print('\\n***** LOADED '+ name+' *****\\n')\n",
    "    print(f'TRAIN SHAPE : {train_embeds.shape}\\nTEST SHAPE : {test_embeds.shape}\\nVAL SHAPE : {val_embeds.shape}\\nY-TRAIN SHAPE : {y_train.shape}\\nY-TEST SHAPE : {y_test.shape}\\nY-VAL SHAPE : {y_val.shape}')\n",
    "\n",
    "    return train_embeds, test_embeds, val_embeds, y_train, y_test, y_val\n",
    "\n",
    "# /kaggle/input/iitpolitenesslevels/SCIBERT_train.pickle\n",
    "name = ''\n",
    "train_embeds, test_embeds, val_embeds, y_train, y_test, y_val = loadPickle(name,is_BiLSTM=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>610</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2717</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>345</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>207</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>138</td>\n",
       "      <td>43</td>\n",
       "      <td>84</td>\n",
       "      <td>45</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>400</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>191</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2084</td>\n",
       "      <td>6</td>\n",
       "      <td>2085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4552</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>348</td>\n",
       "      <td>99</td>\n",
       "      <td>627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4553</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>209</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4556 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  758   759  760  761  762  763   764  \\\n",
       "0     0  0  0  0  0  0  0  0  0  0  ...    0     1  210  610   27   41     8   \n",
       "1     0  0  0  0  0  0  0  0  0  0  ...    1   252    2  307    5    2    11   \n",
       "2     0  0  0  0  0  0  0  0  0  0  ...  345    12   74   14  207    4    20   \n",
       "3     0  0  0  0  0  0  0  0  0  0  ...   54   138   43   84   45   91     1   \n",
       "4     0  0  0  0  0  0  0  0  0  0  ...    6  1089    1    1   43   14   191   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ...   ...  ...  ...  ...  ...   ...   \n",
       "4551  0  0  0  0  0  0  0  0  0  0  ...    0     0    0    0    0    1  2084   \n",
       "4552  0  0  0  0  0  0  0  0  0  0  ...   16    77    4  172  101    1   348   \n",
       "4553  0  0  0  0  0  0  0  0  0  0  ...    0     0    0    0    0    1    62   \n",
       "4554  0  0  0  0  0  0  0  0  0  0  ...    0     1    5   76   28    3   179   \n",
       "4555  0  0  0  0  0  0  0  0  0  0  ...    0     0    1    5    1    1    24   \n",
       "\n",
       "       765   766  767  \n",
       "0        2   209    1  \n",
       "1     2717    15    1  \n",
       "2        7   136  396  \n",
       "3      342   400  731  \n",
       "4       12    15    1  \n",
       "...    ...   ...  ...  \n",
       "4551     6  2085    1  \n",
       "4552    99   627    1  \n",
       "4553   209    64    1  \n",
       "4554    19     1    1  \n",
       "4555    50   451    1  \n",
       "\n",
       "[4556 rows x 768 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sentences = df_train['review'].tolist()\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20min 9s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    # Extract the CLS token embeddings\n",
    "    sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.41      0.37        34\n",
      "           2       0.44      0.33      0.38        94\n",
      "           3       0.59      0.63      0.61       190\n",
      "           4       0.37      0.45      0.41        62\n",
      "           5       0.50      0.30      0.38        20\n",
      "\n",
      "    accuracy                           0.49       400\n",
      "   macro avg       0.45      0.42      0.43       400\n",
      "weighted avg       0.50      0.49      0.49       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = df_train['Tone'].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings.numpy(), labels, test_size=0.2, random_state=45)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4556, 1999]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTone\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with the correct column name for labels\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert DataFrame to NumPy and split features and labels\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Features\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Labels\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 20% for testing\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure reproducibility\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize and train the classifier\u001b[39;00m\n\u001b[0;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Dev\\mestrado\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Dev\\mestrado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2782\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2786\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2787\u001b[0m )\n",
      "File \u001b[1;32mc:\\Dev\\mestrado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Dev\\mestrado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4556, 1999]"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with custom embeddings\n",
    "\n",
    "labels = df_train['Tone']  # Replace with the correct column name for labels\n",
    "\n",
    "# Convert DataFrame to NumPy and split features and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_embeds.to_numpy(),  # Features\n",
    "    labels,  # Labels\n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=45  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Initialize and train the classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random_state=42`\n",
    "```txt\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "            1       0.29      0.19      0.23        32\n",
    "            2       0.34      0.36      0.35        87\n",
    "            3       0.61      0.68      0.64       194\n",
    "            4       0.45      0.38      0.41        73\n",
    "            5       0.36      0.29      0.32        14\n",
    "\n",
    "    accuracy                            0.50       400\n",
    "   macro avg        0.41      0.38      0.39       400\n",
    "weighted avg        0.49      0.50      0.49       400\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2055    3\n",
       "1961    4\n",
       "1864    3\n",
       "2326    5\n",
       "461     4\n",
       "       ..\n",
       "1638    4\n",
       "1095    3\n",
       "1130    3\n",
       "1294    3\n",
       "860     4\n",
       "Name: Tone, Length: 1999, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n",
    "\n",
    "print('raw text',ohe_df.sample()['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.3048\n",
      "Epoch [2/10], Loss: 1.1274\n",
      "Epoch [3/10], Loss: 1.0527\n",
      "Epoch [4/10], Loss: 0.9804\n",
      "Epoch [5/10], Loss: 0.9147\n",
      "Epoch [6/10], Loss: 0.8971\n",
      "Epoch [7/10], Loss: 0.7944\n",
      "Epoch [8/10], Loss: 0.7318\n",
      "Epoch [9/10], Loss: 0.6748\n",
      "Epoch [10/10], Loss: 0.5818\n",
      "Accuracy: 51.75%\n",
      "CPU times: total: 43.4 s\n",
      "Wall time: 6.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom Dataset class\n",
    "class PolitenessDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = PolitenessDataset(X_train, y_train)\n",
    "test_dataset = PolitenessDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define BiLSTM model\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=n_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer\n",
    "        lstm_out, _ = self.lstm(x.unsqueeze(1))  # Add sequence dimension\n",
    "        lstm_out = self.dropout(lstm_out[:, -1, :])  # Use the last hidden state\n",
    "\n",
    "        # Fully connected layer\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits\n",
    "\n",
    "# Model parameters\n",
    "input_dim = 768  # Dimension of embeddings\n",
    "hidden_dim = 128  # Number of hidden units\n",
    "output_dim = len(np.unique(labels))  # Number of politeness levels\n",
    "n_layers = 2  # Number of LSTM layers\n",
    "dropout = 0.3  # Dropout rate\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = BiLSTMClassifier(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for embeddings, labels in train_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, device, num_epochs=10)\n",
    "\n",
    "# Evaluation loop\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in test_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(embeddings)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
